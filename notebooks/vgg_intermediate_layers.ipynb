{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using VGG (16, 19) model\n",
    "\n",
    "Hook a bunch of shallow and deep layers to extract their features. Then using PCA, reduce their\n",
    "dimensionality and use cosine similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torchvision\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "from typing import Callable\n",
    "from PIL import Image\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import model, register hooks, open and transform images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of the layers to register the hook\n",
    "LAYERS = [11, 30]\n",
    "# List of the dimensions \n",
    "PCAS = [0, 5]\n",
    "\n",
    "# path for the folder that contains the images\n",
    "path = \"../data/preprocess/\"\n",
    "\n",
    "# Define the case that will work on\n",
    "cases = [f.path[19:] for f in os.scandir(path) if f.is_dir()]\n",
    "\n",
    "# import model\n",
    "model = torchvision.models.vgg16(pretrained=True)\n",
    "model_name = \"vgg16\"\n",
    "\n",
    "# Dictionary for the features\n",
    "features = {}\n",
    "\n",
    "# helping function for the hooks\n",
    "def reg_hook(layer: int) -> Callable:\n",
    "    def hook(model, input, output):\n",
    "        features[layer] = output.detach()\n",
    "    return hook\n",
    "    \n",
    "# register hooks for every layer of the list LAYERS\n",
    "for layer in LAYERS:\n",
    "    model.features[layer].register_forward_hook(reg_hook(layer))\n",
    "\n",
    "# transform callable function for the images\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize(224),\n",
    "    torchvision.transforms.CenterCrop(224),\n",
    "#     torchvision.transforms.RandomHorizontalFlip(),\n",
    "#     torchvision.transforms.RandomAffine(degrees=30),\n",
    "    torchvision.transforms.ToTensor(),\n",
    "    torchvision.transforms.Normalize(\n",
    "        mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "    ),\n",
    "])\n",
    "\n",
    "# function to open images and return them as a list\n",
    "def open_images(path: str, case: str, type: str) -> list:\n",
    "    lst = []\n",
    "    for filename in glob.glob(path + case + \"/\" + type + \"/*.JPG\"):\n",
    "        lst.append(Image.open(filename).convert(\"RGB\"))\n",
    "    return lst\n",
    "\n",
    "\n",
    "# function for the feature extraction\n",
    "def extract_features(model: torchvision.models, transform: Callable, images: list, layers: list) -> list:\n",
    "\n",
    "    # inner function to normalize the vector\n",
    "    def normalize(A: np.ndarray) -> np.ndarray:\n",
    "        norm = np.linalg.norm(A)\n",
    "        return A / norm\n",
    "\n",
    "    embeddings = []\n",
    "    \n",
    "    # iterate through all images and save the features in the list\n",
    "    for image in images:\n",
    "        x = transform(image).unsqueeze(0).to(\"cpu\")\n",
    "        _ = model(x)\n",
    "\n",
    "        feats = [normalize(features[layer].cpu().numpy()) for layer in layers]\n",
    "        embeddings.append(feats)\n",
    "        \n",
    "    return embeddings\n",
    "\n",
    "\n",
    "# Two functions for the PCA implementation\n",
    "def pca(image: np.ndarray, dimension: int = 8) -> np.ndarray:\n",
    "    '''A tensor with H x W x C, we reshape it to an array of HW x C (pixels x dimension of data)'''\n",
    "    N = image.shape[2] * image.shape[3] # HxW\n",
    "    C = image.shape[1] # Dimensions: Kernels\n",
    "    X = np.reshape(image, [N, C])\n",
    "    feats = PCA(n_components=dimension).fit_transform(X)\n",
    "    return np.reshape(feats, [image.shape[2], image.shape[3], feats.shape[1]])\n",
    "\n",
    "\n",
    "def reduce_array_with_pca(array: list, dimension=8) -> list:\n",
    "    '''Given an array, reduce the dimensional space of the elements.'''\n",
    "    return [pca(image=image, dimension=dimension) for image in array]\n",
    "\n",
    "\n",
    "# Functions for the similarity\n",
    "def cosine_similarity(A: np.ndarray, B: np.ndarray) -> float:\n",
    "    return np.dot(A, B) / (np.linalg.norm(A) * np.linalg.norm(B))\n",
    "\n",
    "def Average(lst):\n",
    "    return sum(lst) / len(lst)\n",
    "\n",
    "def distance_metric(A: np.ndarray, B: np.ndarray, C: np.ndarray) -> float:\n",
    "    A = A.flatten()\n",
    "    B = B.flatten()\n",
    "    C = C.flatten()\n",
    "    \n",
    "    def transform_dist_to_sim(x: float) -> float:\n",
    "        return 1 / (1 + x)\n",
    "\n",
    "    c1 = cosine_similarity(A, B)\n",
    "    c2 = cosine_similarity(A, C)\n",
    "\n",
    "#     e1 = transform_dist_to_sim(distance.euclidean(A, B))\n",
    "#     e2 = transform_dist_to_sim(distance.euclidean(A, C))\n",
    "\n",
    "    return Average([c1, c2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "for case in cases:\n",
    "\n",
    "    images_before_treatment = open_images(path=path, case=case, type=\"BEFORE\")\n",
    "    images_after_treatment = open_images(path=path, case=case, type=\"AFTER\")\n",
    "\n",
    "    # get the features\n",
    "    before_embeddings = extract_features(model=model, transform=transform, images=images_before_treatment, layers=LAYERS)\n",
    "    after_embeddings = extract_features(model=model, transform=transform, images=images_after_treatment, layers=LAYERS)\n",
    "\n",
    "    # Get the results for every layer and every pca\n",
    "    data = []\n",
    "    for pca_value in PCAS:\n",
    "        pca_before_embeddings = []\n",
    "        pca_after_embeddings = []\n",
    "\n",
    "        if pca_value == 0:\n",
    "            pca_before_embeddings = before_embeddings\n",
    "            pca_after_embeddings = after_embeddings\n",
    "\n",
    "        else:\n",
    "\n",
    "            for index, lst in enumerate(before_embeddings):\n",
    "                bf = [pca(array, dimension=pca_value) for array in before_embeddings[index]]\n",
    "                af = [pca(array, dimension=pca_value) for array in after_embeddings[index]]\n",
    "                pca_before_embeddings.append(bf)\n",
    "                pca_after_embeddings.append(af)\n",
    "\n",
    "\n",
    "        for index, lst in enumerate(pca_before_embeddings[0]):\n",
    "            before = distance_metric(A=pca_before_embeddings[0][index],\n",
    "            B=pca_before_embeddings[1][index],\n",
    "            C=pca_before_embeddings[2][index])\n",
    "\n",
    "            after = distance_metric(A=pca_after_embeddings[0][index],\n",
    "            B=pca_after_embeddings[1][index],\n",
    "            C=pca_after_embeddings[2][index])\n",
    "\n",
    "            data.append((LAYERS[index], pca_value, round(before, 3), round(after, 3)))\n",
    "\n",
    "    # Create a dataframe\n",
    "    df = pd.DataFrame(data, columns=['Layer', 'PCA', 'Before','After'])\n",
    "    # create the csv file\n",
    "    df.to_csv(f'../csv/{case}/{case}_{model_name}_cosine.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For every layer, calculate the cosine similarity and the euclidean distance between the wounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics.pairwise import euclidean_distances\n",
    "# wounds_data = []\n",
    "\n",
    "# # function to transform distance to similarity:\n",
    "# def transform_dist_to_sim(dist: float):\n",
    "#     return 1 / (1 + dist)\n",
    "\n",
    "# for index, layer in enumerate(before_embeddings[0]):\n",
    "#     before_wound = before_embeddings[0][index].flatten()\n",
    "#     after_wound = after_embeddings[0][index].flatten()\n",
    "\n",
    "\n",
    "#     # calculate similarity and euclidean distance\n",
    "#     sim = cosine_similarity(before_wound, after_wound)\n",
    "#     dist = transform_dist_to_sim(np.linalg.norm(before_wound-after_wound))\n",
    "\n",
    "#     wounds_data.append((LAYERS[index], sim, dist))\n",
    "\n",
    "# # Create a dataframe\n",
    "# df_wound = pd.DataFrame(wounds_data, columns=['Layer', 'cosine similarity', 'euclidean'])\n",
    "# # create the csv file\n",
    "# df_wound.to_csv(f'../csv/{case}/{case}_{model_name}_wounds.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9dc8a8809d9b700ddb2236033ba8ac530c2c16b40d8653168a12c5dc60845d01"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
