{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "37ed6404",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import glob\n",
    "import os\n",
    "from skimage.io import imread\n",
    "import numpy as np\n",
    "from ipynb.fs.full.functools import Cases, Data\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50a8331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device      = torch.device('cpu') \n",
    "num_workers = 0\n",
    "image_size  = 224 \n",
    "batch_size  = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "393682b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cases = Cases()\n",
    "data = cases.get_array()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff0617a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "augs = A.Compose([A.Resize(height = image_size, \n",
    "                           width  = image_size),\n",
    "                  A.Normalize(mean = (0, 0, 0),\n",
    "                              std  = (1, 1, 1)),\n",
    "                  ToTensorV2()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d235128e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset\n",
    "image_dataset = Data(data=data, transform=augs)\n",
    "\n",
    "image_loader = DataLoader(image_dataset, \n",
    "                          batch_size  = batch_size, \n",
    "                          shuffle     = False, \n",
    "                          num_workers = 0,\n",
    "                          pin_memory  = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "32611de2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 59/59 [00:00<00:00, 146.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: tensor([0.4247, 0.4662, 0.6567])\n",
      "std:  tensor([0.1296, 0.1301, 0.1386])\n"
     ]
    }
   ],
   "source": [
    "psum    = torch.tensor([0.0, 0.0, 0.0])\n",
    "psum_sq = torch.tensor([0.0, 0.0, 0.0])\n",
    "\n",
    "# loop through images\n",
    "for inputs in tqdm(image_loader):\n",
    "    psum    += inputs.sum(axis        = [0, 2, 3])\n",
    "    psum_sq += (inputs ** 2).sum(axis = [0, 2, 3])\n",
    "    \n",
    "# pixel count\n",
    "count = len(image_dataset) * image_size * image_size\n",
    "\n",
    "# mean and std\n",
    "total_mean = psum / count\n",
    "total_var  = (psum_sq / count) - (total_mean ** 2)\n",
    "total_std  = torch.sqrt(total_var)\n",
    "\n",
    "# output\n",
    "print('mean: '  + str(total_mean))\n",
    "print('std:  '  + str(total_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c765140",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a927d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (thesis)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
